axis(1, at = 1:21, labels=0:20)
plot(lrirf$irf$Interest.Rates[,3], xlab = "Periods after shock", ylab = "Investment growth", xaxt = "n")
axis(1, at = 1:21, labels=0:20)
plot(lrirf$irf$Prices[,3], xlab = "Periods after shock", ylab = "Investment growth", xaxt = "n")
axis(1, at = 1:21, labels=0:20)
# New................
gerirf <- irf(GerVAR3, n.ahead = 20, ortho = TRUE)
plot(gerirf$irf$Output[,1], xlab = "Periods after shock", ylab = "Investment growth", xaxt = "n")
plot(gerirf$irf$Interest.Rates[,1], xlab = "Periods after shock", ylab = "Investment growth", xaxt = "n")
plot(gerirf$irf$Prices[,1], xlab = "Periods after shock", ylab = "Investment growth", xaxt = "n")
plot(gerirf$irf$Output[,2], xlab = "Periods after shock", ylab = "Investment growth", xaxt = "n")
plot(gerirf$irf$Interest.Rates[,2], xlab = "Periods after shock", ylab = "Investment growth", xaxt = "n")
plot(gerirf$irf$Prices[,2], xlab = "Periods after shock", ylab = "Investment growth", xaxt = "n")
plot(gerirf$irf$Output[,3], xlab = "Periods after shock", ylab = "Investment growth", xaxt = "n")
plot(gerirf$irf$Interest.Rates[,3], xlab = "Periods after shock", ylab = "Investment growth", xaxt = "n")
plot(gerirf$irf$Prices[,3], xlab = "Periods after shock", ylab = "Investment growth", xaxt = "n")
v1 <- GerVAR3
x1 <- id.chol(v1)
x2 <- id.chol(v1, order_k = c("pi", "x", "i")) ## order_k = c(2,1,3)
summary(x1)
# impulse response analysis
i1 <- irf(x1, n.ahead = 30)
i2 <- irf(x2, n.ahead = 30)
plot(i1, scales = 'free_y')
plot(i2, scales = 'free_y')
v1 <- GerVAR3
x1 <- id.chol(v1)
x2 <- id.chol(v1, order_k = c("pi", "x", "i")) ## order_k = c(2,1,3)
x2 <- id.chol(v1, order_k = c("Output", "Prices", "Interest Rates")) ## order_k = c(2,1,3)
View(x1)
x2 <- id.chol(v1, order_k = c(1, 2, 3)) ## order_k = c(2,1,3)
summary(x1)
# impulse response analysis
i1 <- irf(x1, n.ahead = 30)
i2 <- irf(x2, n.ahead = 30)
plot(i1, scales = 'free_y')
plot(i2, scales = 'free_y')
plot(i1, scales = 'free_y')
## Data Cleaning
# Loading data
data <- read.csv("currency_exchange_rates_02-01-1995_-_02-05-2018.csv", header = TRUE)
# Selecting relevant columns from data
datac <- read.csv(file = "currency_exchange_rates_02-01-1995_-_02-05-2018.csv")[ ,c('Date', 'Euro')]
# Create a sequence of dates using the first column of the data, which is not recognized as dates yet, with the format corresponding to the format in er$DATE, i.e. year-month-day
dates <- as.Date(datac$Date, format = "%Y-%m-%d")
# Create a zoo time series (due to missing variables)
erdata <- zoo(x = datac$Euro, order.by = dates)
plot(erdata, type="l")
# Split data into training and testing set, for calculating accuracy
train <- head(erdata, n=-20)
test <- tail(erdata, n=20)
train[as.Date(c("2010-08-19"))]
erdata <- as.xts(train)
train['2010-08-19']
plot.xts(erdata)
## Training ARIMA Model
ermodel <- auto.arima(erdata, max.p = 5, max.q = 5, max.d = 2, test = c("adf"))
summary(ermodel)
plot.xts(diff(erdata,1))
# Diagnostics
# Serial Autocorrelation - BG Test
Acf(diff(erdata,1))
# Partial Autocorrelation
Pacf(diff(erdata,1))
# Forecast
fore <- forecast(ermodel, h = 500)
plot(fore)
test[1,1]
# Compare final results
trainedForecast <- fore$fitted[1:20]
# Calculate MAPE
mean(abs((trainedForecast - test[1:20])/test[1:20]), na.rm=TRUE)
# Compare final results
trainedForecast <- fore$fitted[1:20]
# Calculate MAPE
mean(abs((trainedForecast - test[1:20])/test[1:20]), na.rm=TRUE)
# Plotting forecast vs actual values
x  <- seq(as.Date("2018/4/5"), as.Date("2018/4/25"), "days")
xyplot(test[1:20] + trainedForecast ~ x, data, col=c("steelblue", "#69b3a2"), lwd=2, ylab = "Estimation vs True Value", xlab = "Date of Estimation")
#MAPE shows a mean percentage error of only 0.47%
# Showing 20 out of sample (test set) shows relatively accurate results with an average our of sample error of 5%
# colSums(!is.na(datac)) # Checking number of observations that are not NA
# Plotting forecast vs actual values
x  <- seq(as.Date("2018/4/5"), as.Date("2018/4/25"), "days")
xyplot(test[1:20] + trainedForecast ~ x, data, col=c("steelblue", "#69b3a2"), lwd=2, ylab = "Estimation vs True Value", xlab = "Date of Estimation")
## ARIMA
# Install and load necessary packages:
# install.packages("xts")
# install.packages("forecast")
# install.packages("latticeExtra")
library(zoo)
library(xts)
library(forecast)
library(urca)
library(dplyr)
library(latticeExtra)
## Data Cleaning
# Loading data
data <- read.csv("currency_exchange_rates_02-01-1995_-_02-05-2018.csv", header = TRUE)
# Selecting relevant columns from data
datac <- read.csv(file = "currency_exchange_rates_02-01-1995_-_02-05-2018.csv")[ ,c('Date', 'Euro')]
# Create a sequence of dates using the first column of the data, which is not recognized as dates yet, with the format corresponding to the format in er$DATE, i.e. year-month-day
dates <- as.Date(datac$Date, format = "%Y-%m-%d")
# Create a zoo time series (due to missing variables)
erdata <- zoo(x = datac$Euro, order.by = dates)
plot(erdata, type="l")
# Split data into training and testing set, for calculating accuracy
train <- head(erdata, n=-20)
test <- tail(erdata, n=20)
train[as.Date(c("2010-08-19"))]
erdata <- as.xts(train)
train['2010-08-19']
plot.xts(erdata)
## Training ARIMA Model
ermodel <- auto.arima(erdata, max.p = 5, max.q = 5, max.d = 2, test = c("adf"))
summary(ermodel)
plot.xts(diff(erdata,1))
# Diagnostics
# Serial Autocorrelation - BG Test
Acf(diff(erdata,1))
# Partial Autocorrelation
Pacf(diff(erdata,1))
# Forecast
fore <- forecast(ermodel, h = 500)
plot(fore)
test[1,1]
# Compare final results
trainedForecast <- fore$fitted[1:20]
# Calculate MAPE
mean(abs((trainedForecast - test[1:20])/test[1:20]), na.rm=TRUE)
# Plotting forecast vs actual values
x  <- seq(as.Date("2018/4/5"), as.Date("2018/4/25"), "days")
#xyplot(test[1:20] + trainedForecast ~ x, data, col=c("steelblue", "#69b3a2"), lwd=2, ylab = "Estimation vs True Value", xlab = "Date of Estimation")
#MAPE shows a mean percentage error of only 0.47%
# Showing 20 out of sample (test set) shows relatively accurate results with an average our of sample error of 5%
# colSums(!is.na(datac)) # Checking number of observations that are not NA
View(ermodel)
View(data)
View(datac)
summary(ur.df(erdata, type = c("trend"), lags = 8, selectlags = c("AIC")))
## ARIMA
# Install and load necessary packages:
# install.packages("xts")
# install.packages("forecast")
# install.packages("latticeExtra")
library(zoo)
library(xts)
library(forecast)
library(urca)
library(dplyr)
library(latticeExtra)
## Data Cleaning
# Loading data
data <- read.csv("currency_exchange_rates_02-01-1995_-_02-05-2018.csv", header = TRUE)
# Selecting relevant columns from data
datac <- read.csv(file = "currency_exchange_rates_02-01-1995_-_02-05-2018.csv")[ ,c('Date', 'Euro')]
# Create a sequence of dates using the first column of the data, which is not recognized as dates yet, with the format corresponding to the format in er$DATE, i.e. year-month-day
dates <- as.Date(datac$Date, format = "%Y-%m-%d")
# Create a zoo time series (due to missing variables)
erdata <- zoo(x = datac$Euro, order.by = dates)
plot(erdata, type="l")
# Split data into training and testing set, for calculating accuracy
train <- head(erdata, n=-20)
test <- tail(erdata, n=20)
train[as.Date(c("2010-08-19"))]
erdata <- as.xts(train)
train['2010-08-19']
plot.xts(erdata)
## Training ARIMA Model
ermodel <- auto.arima(erdata, max.p = 5, max.q = 5, max.d = 2, test = c("adf"))
summary(ermodel)
plot.xts(diff(erdata,1))
# Diagnostics
# Serial Autocorrelation - BG Test
Acf(diff(erdata,1))
# Partial Autocorrelation
Pacf(diff(erdata,1))
summary(ur.df(erdata, type = c("trend"), lags = 8, selectlags = c("AIC")))
# Forecast
fore <- forecast(ermodel, h = 500)
plot(fore)
test[1,1]
# Compare final results
trainedForecast <- fore$fitted[1:20]
# Calculate MAPE
mean(abs((trainedForecast - test[1:20])/test[1:20]), na.rm=TRUE)
# Plotting forecast vs actual values
x  <- seq(as.Date("2018/4/5"), as.Date("2018/4/25"), "days")
#xyplot(test[1:20] + trainedForecast ~ x, data, col=c("steelblue", "#69b3a2"), lwd=2, ylab = "Estimation vs True Value", xlab = "Date of Estimation")
#MAPE shows a mean percentage error of only 0.47%
# Showing 20 out of sample (test set) shows relatively accurate results with an average our of sample error of 5%
# colSums(!is.na(datac)) # Checking number of observations that are not NA
adf.test(x, nlag = NULL, output = TRUE)
# Serial Autocorrelation - BG Test
Acf(diff(erdata,1))
adf.test(erdata, nlag = NULL, output = TRUE)
# Install and load necessary packages:
# install.packages("xts")
# install.packages("forecast")
# install.packages("latticeExtra")
install.packages("adf")
summary(ur.df(na.remove(erdata), type = c("trend"), lags = 8, selectlags = c("AIC")))
ur.df(na.remove(erdata), type = c("trend"), lags = 8, selectlags = c("AIC")
summary(ur.df(na.omit(erdata), type = c("trend"), lags = 8, selectlags = c("AIC")))
na.omit(erdata)
nonadata <- na.omit(erdata)
summary(ur.df(nonadata, type = c("trend"), lags = 8, selectlags = c("AIC")))
dlexp <- diff(nonadata,1)
dlexp <- dlexp[-1,] # to remove the first row, which will now be NA as we have taken the difference
summary(ur.df(dlexp, type = c("drift"), lags = 8, selectlags = c("AIC")))
plot.xts(dlexp)
# ADF Test
nonadata <- na.omit(erdata)
summary(ur.df(nonadata, type = c("drift"), lags = 8, selectlags = c("AIC")))
plot.xts(dlexp)
# ADF Test
nonadata <- na.omit(erdata)
dlexp <- diff(nonadata,1)
dlexp <- dlexp[-1,] # to remove the first row, which will now be NA as we have taken the difference
summary(ur.df(nonadata, type = c("drift"), lags = 8, selectlags = c("AIC")))
summary(ur.kpss(nonadata, type = c("tau")))
summary(ur.kpss(nonadata, type = c("tau")))
# ADF Test
nonadata <- na.omit(erdata)
dlexp <- diff(nonadata,1)
dlexp <- diff(erdata,1)
summary(ur.df(nonadata, type = c("drift"), lags = 8, selectlags = c("AIC")))
plot.xts(dlexp)
erdata <- diff(erdata)
View(erdata)
#dlexp <- diff(nonadata,1)
dlexp <- log(nonadata)
# ADF Test
nonadata <- na.omit(erdata)
#dlexp <- diff(nonadata,1)
dlexp <- log(nonadata)
dlexp <- dlexp[-1,] # to remove the first row, which will now be NA as we have taken the difference
# ADF Test
nonadata <- na.omit(erdata)
#dlexp <- diff(nonadata,1)
dlexp <- log(nonadata)
dlexp <- dlexp[-1,] # to remove the first row, which will now be NA as we have taken the difference
summary(ur.df(nonadata, type = c("drift"), lags = 8, selectlags = c("AIC")))
## ARIMA
# Install and load necessary packages:
# install.packages("xts")
# install.packages("forecast")
# install.packages("latticeExtra")
library(zoo)
library(xts)
library(forecast)
library(urca)
library(dplyr)
library(latticeExtra)
## Data Cleaning
# Loading data
data <- read.csv("currency_exchange_rates_02-01-1995_-_02-05-2018.csv", header = TRUE)
# Selecting relevant columns from data
datac <- read.csv(file = "currency_exchange_rates_02-01-1995_-_02-05-2018.csv")[ ,c('Date', 'Euro')]
# Create a sequence of dates using the first column of the data, which is not recognized as dates yet, with the format corresponding to the format in er$DATE, i.e. year-month-day
dates <- as.Date(datac$Date, format = "%Y-%m-%d")
# Create a zoo time series (due to missing variables)
erdata <- zoo(x = datac$Euro, order.by = dates)
plot(erdata, type="l")
# Split data into training and testing set, for calculating accuracy
train <- head(erdata, n=-20)
test <- tail(erdata, n=20)
train[as.Date(c("2010-08-19"))]
erdata <- as.xts(train)
train['2010-08-19']
plot.xts(erdata)
## Training ARIMA Model
ermodel <- auto.arima(erdata, max.p = 5, max.q = 5, max.d = 2, test = c("adf"))
summary(ermodel)
# Diagnostics
# Serial Autocorrelation - BG Test
Acf(diff(erdata,1))
# Partial Autocorrelation
Pacf(diff(erdata,1))
# ADF Test
nonadata <- na.omit(erdata)
lnonadata <- log(nonadata)
lnonadata <- lnonadata[-1,] # to remove the first row, which will now be NA as we have taken the difference
summary(ur.df(lnonadata, type = c("drift"), lags = 8, selectlags = c("AIC")))
plot.xts(lnonadata)
summary(ur.kpss(nonadata, type = c("tau")))
# Forecast
fore <- forecast(ermodel, h = 500)
plot(fore)
test[1,1]
# Compare final results
trainedForecast <- fore$fitted[1:20]
# Calculate MAPE
mean(abs((trainedForecast - test[1:20])/test[1:20]), na.rm=TRUE)
# Plotting forecast vs actual values
x  <- seq(as.Date("2018/4/5"), as.Date("2018/4/25"), "days")
#xyplot(test[1:20] + trainedForecast ~ x, data, col=c("steelblue", "#69b3a2"), lwd=2, ylab = "Estimation vs True Value", xlab = "Date of Estimation")
#MAPE shows a mean percentage error of only 0.47%
# Showing 20 out of sample (test set) shows relatively accurate results with an average our of sample error of 5%
# colSums(!is.na(datac)) # Checking number of observations that are not NA
summary(ur.df(lnonadata, type = c("drift"), lags = 8, selectlags = c("AIC")))
summary(ur.kpss(lnonadata, type = c("tau")))
plot(erdata, type="l", xlab="Stuff")
library(stargazer)
#MAPE shows a mean percentage error of only 0.47%
# Showing 20 out of sample (test set) shows relatively accurate results with an average our of sample error of 5%
# colSums(!is.na(datac)) # Checking number of observations that are not NA
stargazer(summary(ur.df(nonadata, type = c("drift"), lags = 8, selectlags = c("AIC"))))
## VAR
# Install and load necessary packages if needed:
#install.packages("vars")
#install.packages("svars")
library(vars)
library(svars)
## Data Preparation
priceData <- read.csv("var_data/cpih.csv", header = TRUE)
intData <- read.csv("var_data/interest_rate.csv", header = TRUE)
gdpData <- read.csv("var_data/gdp.csv", header = TRUE)
# Check starting point of quarterly data
gdpData[216,1]
intData[121,1]
priceData[39,1]
# Check endpoint of quarterly data
gdpData[296,1]
intData[201,1]
priceData[119,1]
# Joining data
dataa <- gdpData[216:296,1:2]
datab <- intData[121:201,1:2]
datac <- priceData[39:119,1:2]
finalData <- dataa
finalData <- cbind(finalData, datab[,2], datac[,2])
#Formatting data
names(finalData)[1] <- "Date"
names(finalData)[2] <- "Output"
names(finalData)[3] <- "Interest Rates"
names(finalData)[4] <- "Prices"
data <- finalData[,2:4]
# Updating data types to be fed into model
data$Output <- as.numeric(data$Output)
data$Output <- log(data$Output)
data$`Interest Rates` <- as.numeric(data$`Interest Rates`)
data$`Interest Rates` <- log(data$`Interest Rates`)
data$Prices <- as.numeric(data$Prices)
data$Prices <- log(data$Prices)
vardata <- as.ts(data, start = c(1989,2), frequency = 4)
## Training VAR Model
GerVAR <- VAR(vardata, p = 2, type = c("const"), ic = c("AIC"))
# Assesing Lag order
VARselect(vardata, lag.max = 10, type = c("const"))$selection
GerVAR3 <- VAR(vardata, p = 3, type = c("const"), ic = c("AIC"))
## Diagnostics
# Testing for Atocorrelation: Breusch-Godfrey and the order of the test as 6
serial.test(GerVAR, lags.bg = 6, type = c("BG"))
serial.test(GerVAR3, lags.bg = 6, type = c("BG"))
normality.test(GerVAR3)
summary(GerVAR3)
# we can produce the impulse response functions:
n <- 20
GerIRF <- irf(GerVAR3, n.ahead = n, ortho = FALSE)
#where the first argument is the estimated VAR, n.ahead is the number of periods that we want to see the impulses for and ortho = FALSE relates to something to be covered in week 8
# Plot impulse responses:
plot(GerIRF$irf$Interest.Rates[,1]) # column 1 of the IRF of investment
plot(GerIRF$irf$Output[,1]) # column 1 of the IRF of investment
plot(GerIRF$irf$Prices[,1]) # column 1 of the IRF of investment
# naming graph plot(GerIRF$irf$inv[,1], xlab = "Periods after shock", ylab = "Investment growth", xaxt = "n")
# https://engage.bath.ac.uk/learn/pluginfile.php/42047/mod_assign/intro/Recursive%20VARs.nb.html
# Structural VAR:
v1 <- GerVAR3
# identify the structural impact matrix of the corresponding SVAR model
x1 <- id.chol(v1)
summary(x1)
# impulse response analysis
i1 <- irf(x1, n.ahead = 30)
plot(i1, scales = 'free_y')
## VAR
# Install and load necessary packages if needed:
#install.packages("vars")
#install.packages("svars")
library(vars)
library(svars)
## Data Preparation
priceData <- read.csv("var_data/cpih.csv", header = TRUE)
intData <- read.csv("var_data/interest_rate.csv", header = TRUE)
gdpData <- read.csv("var_data/gdp.csv", header = TRUE)
# Check starting point of quarterly data
gdpData[216,1]
intData[121,1]
priceData[39,1]
# Check endpoint of quarterly data
gdpData[296,1]
intData[201,1]
priceData[119,1]
# Joining data
dataa <- gdpData[216:296,1:2]
datab <- intData[121:201,1:2]
datac <- priceData[39:119,1:2]
finalData <- dataa
finalData <- cbind(finalData, datab[,2], datac[,2])
#Formatting data
names(finalData)[1] <- "Date"
names(finalData)[2] <- "Output"
names(finalData)[3] <- "Interest Rates"
names(finalData)[4] <- "Prices"
data <- finalData[,2:4]
# Updating data types to be fed into model
data$Output <- as.numeric(data$Output)
data$Output <- log(data$Output)
data$`Interest Rates` <- as.numeric(data$`Interest Rates`)
data$`Interest Rates` <- log(data$`Interest Rates`)
data$Prices <- as.numeric(data$Prices)
data$Prices <- log(data$Prices)
vardata <- as.ts(data, start = c(1989,2), frequency = 4)
## Training VAR Model
GerVAR <- VAR(vardata, p = 2, type = c("const"), ic = c("AIC"))
# Assesing Lag order
VARselect(vardata, lag.max = 10, type = c("const"))$selection
GerVAR3 <- VAR(vardata, p = 3, type = c("const"), ic = c("AIC"))
## Diagnostics
# Testing for Atocorrelation: Breusch-Godfrey and the order of the test as 6
serial.test(GerVAR, lags.bg = 6, type = c("BG"))
serial.test(GerVAR3, lags.bg = 6, type = c("BG"))
normality.test(GerVAR3)
summary(GerVAR3)
# we can produce the impulse response functions:
n <- 20
GerIRF <- irf(GerVAR3, n.ahead = n, ortho = FALSE)
#where the first argument is the estimated VAR, n.ahead is the number of periods that we want to see the impulses for and ortho = FALSE relates to something to be covered in week 8
# Plot impulse responses:
plot(GerIRF$irf$Interest.Rates[,1]) # column 1 of the IRF of investment
plot(GerIRF$irf$Output[,1]) # column 1 of the IRF of investment
plot(GerIRF$irf$Prices[,1]) # column 1 of the IRF of investment
# naming graph plot(GerIRF$irf$inv[,1], xlab = "Periods after shock", ylab = "Investment growth", xaxt = "n")
# https://engage.bath.ac.uk/learn/pluginfile.php/42047/mod_assign/intro/Recursive%20VARs.nb.html
# Structural VAR:
v1 <- GerVAR3
# identify the structural impact matrix of the corresponding SVAR model
x1 <- id.chol(v1)
summary(x1)
# impulse response analysis
i1 <- irf(x1, n.ahead = 30)
plot(i1, scales = 'free_y')
View(data)
View(dataa)
View(datab)
rmarkdown::render("VAR_assignment_2.R", "pdf_document")
## ARIMA Model
# Install and load necessary libraries
library(zoo)
library(xts)
library(forecast)
library(urca)
library(dplyr)
library(latticeExtra)
## Data Cleaning
# Loading data
data <- read.csv("currency_exchange_rates_02-01-1995_-_02-05-2018.csv", header = TRUE)
# Selecting relevant columns from data
datac <- read.csv(file = "currency_exchange_rates_02-01-1995_-_02-05-2018.csv")[ ,c('Date', 'Euro')]
# Create a sequence of dates using the first column of the data, which is not recognized as dates yet, with the format corresponding to the format in er$DATE, i.e. year-month-day
dates <- as.Date(datac$Date, format = "%Y-%m-%d")
# Create a zoo time series (due to missing variables)
erdata <- zoo(x = datac$Euro, order.by = dates)
plot(erdata, type="l", xlab="Stuff")
# Split data into training and testing set, for calculating accuracy
train <- head(erdata, n=-20)
test <- tail(erdata, n=20)
erdata <- as.xts(train)
# Plot training data
plot.xts(erdata)
## Training ARIMA Model
ermodel <- auto.arima(erdata, max.p = 5, max.q = 5, max.d = 2, test = c("adf"))
summary(ermodel)
# Diagnostics
# Serial Autocorrelation - BG Test
Acf(diff(erdata,1))
# Partial Autocorrelation
Pacf(diff(erdata,1))
# ADF Test for Stationarity
nonadata <- na.omit(erdata)
summary(ur.df(nonadata, type = c("drift"), lags = 8, selectlags = c("AIC")))
plot.xts(diff(nonadata,1))
# Forecasting using trained model
fore <- forecast(ermodel, h = 500)
plot(fore)
test[1,1]
# Compare final results
trainedForecast <- fore$fitted[1:20]
# Calculate MAPE
mean(abs((trainedForecast - test[1:20])/test[1:20]), na.rm=TRUE)
# Plotting forecast vs actual values
x  <- seq(as.Date("2018/4/5"), as.Date("2018/4/25"), "days")
xyplot(test[1:20] + trainedForecast ~ x, data, col=c("steelblue", "#69b3a2"), lwd=2, ylab = "Estimation vs True Value", xlab = "Date of Estimation")
# Plotting forecast vs actual values
x  <- seq(as.Date("2018/4/5"), as.Date("2018/4/25"), "days")
xyplot(test[1:20] + trainedForecast ~ x, data, col=c("steelblue", "#69b3a2"), lwd=2, ylab = "Estimation vs True Value", xlab = "Date of Estimation")
xyplot(test[1:20] + trainedForecast ~ x, erdata, col=c("steelblue", "#69b3a2"), lwd=2, ylab = "Estimation vs True Value", xlab = "Date of Estimation")
xyplot(test[1:20] + trainedForecast ~ x, col=c("steelblue", "#69b3a2"), lwd=2, ylab = "Estimation vs True Value", xlab = "Date of Estimation")
trainedForecast
# Plotting forecast vs actual values
x  <- seq(as.Date("2018/4/5"), as.Date("2018/4/25"))
, "days")
# Plotting forecast vs actual values
x  <- seq(as.Date("2018/4/5"), as.Date("2018/4/25"), "days")
xyplot(test[1:20] + trainedForecast ~ x, data, col=c("steelblue", "#69b3a2"), lwd=2, ylab = "Estimation vs True Value", xlab = "Date of Estimation")
# Plotting forecast vs actual values
x  <- seq(1, as.Date("2018/4/5"), as.Date("2018/4/25"), "days")
# Plotting forecast vs actual values
x  <- seq(20, as.Date("2018/4/5"), as.Date("2018/4/25"), "days")
# Plotting forecast vs actual values
x  <- seq(as.Date("2018/4/5"), as.Date("2018/4/25"), "days")
xyplot(test[1:20] + trainedForecast ~ x, data, col=c("steelblue", "#69b3a2"), lwd=2, ylab = "Estimation vs True Value", xlab = "Date of Estimation")
